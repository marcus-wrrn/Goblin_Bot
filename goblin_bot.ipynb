{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from fractions import Fraction\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16405"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "dfWin = pd.read_csv(\"./DataFrames/WinnersProcessed.csv\", index_col=0).dropna(subset=[\"expected_dmg\"]).reset_index(drop=True)\n",
    "dfLose = pd.read_csv(\"./DataFrames/LosersProcessed.csv\", index_col=0).dropna(subset=[\"expected_dmg\"]).reset_index(drop=True)\n",
    "len(dfWin)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forgot to put which side the winner and loser were on, therefore I need to randomize where to put the winning creature and where to put the losing creature.\n",
    "This will allow the model from not constantly predicting the creature on a specific side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Returns all stat values of a dataframe as a 2d array\n",
    "def getStatsValues(df: pd.DataFrame):\n",
    "    return df.loc[:, [\"cr\", \"hp\", \"str\", \"dex\", \"con\", \"int\", \"wis\", \"cha\", \"ac\", \"spd\", \"expected_dmg\"]].values\n",
    "\n",
    "def convertToFloat(val):\n",
    "    if type(val) == str:\n",
    "        return float(Fraction(val))\n",
    "    else:\n",
    "        return float(val)\n",
    "\n",
    "dfWin[\"cr\"] = dfWin.apply(lambda row: convertToFloat(row[\"cr\"]), axis=1)\n",
    "dfLose[\"cr\"] = dfLose.apply(lambda row: convertToFloat(row[\"cr\"]), axis=1)\n",
    "# Get Input values\n",
    "dfWinStats = getStatsValues(dfWin)\n",
    "dfLoseStats = getStatsValues(dfLose)\n",
    "# Append input values together\n",
    "dfStats = np.concatenate([dfWinStats, dfLoseStats], axis=1)\n",
    "# Generate random list representing which side won and which side lost\n",
    "\n",
    "# Make the right side outputs equal 1\n",
    "rightSide = np.ones(dfStats.shape[0]//2)\n",
    "# Make left side be zero\n",
    "leftSide = np.zeros(dfStats.shape[0]//2)\n",
    "# Append all values to targets\n",
    "targets = np.append(leftSide, rightSide)\n",
    "# Shuffle results\n",
    "random.shuffle(targets)\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(dfWinStats.shape[0] - 1):\n",
    "    if targets[i]:\n",
    "        res = np.concatenate([dfLoseStats[i], dfWinStats[i]])\n",
    "    else:\n",
    "        res = np.concatenate([dfWinStats[i], dfLoseStats[i]])\n",
    "    data.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5862069 , 0.5625    , 0.35      , ..., 0.51785714, 0.38181818,\n",
       "        0.3561021 ],\n",
       "       [0.48275862, 0.4375    , 0.5       , ..., 0.55357143, 0.50909091,\n",
       "        0.4216353 ],\n",
       "       [0.68965517, 0.5       , 0.45      , ..., 0.5       , 0.43636364,\n",
       "        0.40455855],\n",
       "       ...,\n",
       "       [0.48275862, 0.5       , 0.5       , ..., 0.58928571, 0.49090909,\n",
       "        0.41263391],\n",
       "       [0.62068966, 0.5625    , 0.75      , ..., 0.51785714, 0.47272727,\n",
       "        0.41293179],\n",
       "       [0.62068966, 0.5       , 0.4       , ..., 0.51785714, 0.54545455,\n",
       "        0.4228873 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertToFloat(val):\n",
    "    if type(val) == str:\n",
    "        return float(Fraction(val))\n",
    "    else:\n",
    "        return float(val)\n",
    "\n",
    "def getDifData(df1: pd.DataFrame, df2: pd.DataFrame, targets: list, stats=['ac', 'cr', 'spd', 'hp', 'str', 'dex', 'con', 'int', 'wis', 'cha', 'expected_dmg']):\n",
    "    vals = np.zeros((df1.shape[0], len(stats)))\n",
    "    for (i, r1), (_, r2) in zip(df1.iterrows(), df2.iterrows()):\n",
    "        for j, stat in enumerate(stats):\n",
    "            # If a stat is greater than a believable amount make the stat equal to its opponent\n",
    "            # This allows for better generalization of the data\n",
    "            if r1[stat] >= 900: r1[stat] = r2[stat]\n",
    "            if r2[stat] >= 900: r2[stat] = r1[stat]\n",
    "            vals[i, j] = r1[stat] - r2[stat] if targets[i] else r2[stat] - r1[stat]\n",
    "    return vals\n",
    "\n",
    "\n",
    "rightSize = dfWin.shape[0]//2\n",
    "leftSize = dfWin.shape[0] - rightSize\n",
    "# Make the right side outputs equal 1\n",
    "rightSide = np.ones(rightSize)\n",
    "# Make left side be zero\n",
    "leftSide = np.zeros(leftSize)\n",
    "# Append all values to targets\n",
    "targets = np.append(leftSide, rightSide)\n",
    "# Shuffle results\n",
    "random.shuffle(targets)\n",
    "\n",
    "\n",
    "dfWin[\"cr\"] = dfWin.apply(lambda row: convertToFloat(row[\"cr\"]), axis=1)\n",
    "dfLose[\"cr\"] = dfLose.apply(lambda row: convertToFloat(row[\"cr\"]), axis=1)\n",
    "\n",
    "data = getDifData(dfWin, dfLose, targets)\n",
    "\n",
    "# Create scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find better ways to normalize results does not work currently\n",
    "\n",
    "# def normalize(point):\n",
    "#     if not point:\n",
    "#         return 0\n",
    "#     else: return 1/point\n",
    "\n",
    "# for i in range(data.shape[0]):\n",
    "#     for j in range(data.shape[1]):\n",
    "#         data[i,j] = normalize(data[i,j])\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One: 8202\n",
      "Zero: 8203\n"
     ]
    }
   ],
   "source": [
    "# Get the distribution of target values\n",
    "\n",
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "for val in targets:\n",
    "    if val:\n",
    "        one += 1\n",
    "    else:\n",
    "        zero += 1\n",
    "\n",
    "print(f\"One: {one}\")\n",
    "print(f\"Zero: {zero}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitSize = 0.70\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=(1-splitSize), random_state=47)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =     12064001     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.93644D-01    |proj g|=  1.33468D-02\n",
      "\n",
      "At iterate    1    f=  6.93008D-01    |proj g|=  9.70227D-03\n",
      "\n",
      "At iterate    2    f=  6.92878D-01    |proj g|=  5.05398D-03\n",
      "\n",
      "At iterate    3    f=  6.92662D-01    |proj g|=  1.05719D-03\n",
      "\n",
      "At iterate    4    f=  6.91985D-01    |proj g|=  8.66735D-03\n",
      "\n",
      "At iterate    5    f=  6.90407D-01    |proj g|=  2.13345D-02\n",
      "\n",
      "At iterate    6    f=  6.86431D-01    |proj g|=  3.81023D-02\n",
      "\n",
      "At iterate    7    f=  6.73700D-01    |proj g|=  4.05586D-02\n",
      "\n",
      "At iterate    8    f=  6.64872D-01    |proj g|=  2.06024D-02\n",
      "\n",
      "At iterate    9    f=  6.64644D-01    |proj g|=  5.75320D-03\n",
      "\n",
      "At iterate   10    f=  6.64138D-01    |proj g|=  3.33057D-03\n",
      "\n",
      "At iterate   11    f=  6.63953D-01    |proj g|=  6.22719D-03\n",
      "\n",
      "At iterate   12    f=  6.63522D-01    |proj g|=  7.31038D-03\n",
      "\n",
      "At iterate   13    f=  6.61599D-01    |proj g|=  5.30433D-03\n",
      "\n",
      "At iterate   14    f=  6.56065D-01    |proj g|=  1.35023D-02\n",
      "\n",
      "At iterate   15    f=  6.54621D-01    |proj g|=  1.53534D-02\n",
      "\n",
      "At iterate   16    f=  6.53376D-01    |proj g|=  5.07218D-03\n",
      "\n",
      "At iterate   17    f=  6.52545D-01    |proj g|=  7.47182D-04\n",
      "\n",
      "At iterate   18    f=  6.52274D-01    |proj g|=  6.99964D-04\n",
      "\n",
      "At iterate   19    f=  6.48720D-01    |proj g|=  7.85868D-03\n",
      "\n",
      "At iterate   20    f=  6.47704D-01    |proj g|=  1.87827D-03\n",
      "\n",
      "At iterate   21    f=  6.47569D-01    |proj g|=  3.40850D-04\n",
      "\n",
      "At iterate   22    f=  6.47482D-01    |proj g|=  3.64607D-04\n",
      "\n",
      "At iterate   23    f=  6.46532D-01    |proj g|=  2.20004D-03\n",
      "\n",
      "At iterate   24    f=  6.45910D-01    |proj g|=  1.05561D-02\n",
      "\n",
      "At iterate   25    f=  6.45528D-01    |proj g|=  8.12185D-03\n",
      "\n",
      "At iterate   26    f=  6.45394D-01    |proj g|=  1.68758D-04\n",
      "\n",
      "At iterate   27    f=  6.45380D-01    |proj g|=  2.01823D-04\n",
      "\n",
      "At iterate   28    f=  6.45161D-01    |proj g|=  2.56437D-04\n",
      "\n",
      "At iterate   29    f=  6.45156D-01    |proj g|=  1.21594D-03\n",
      "\n",
      "At iterate   30    f=  6.45149D-01    |proj g|=  6.13688D-04\n",
      "\n",
      "At iterate   31    f=  6.45145D-01    |proj g|=  1.62601D-04\n",
      "\n",
      "At iterate   32    f=  6.45142D-01    |proj g|=  1.43629D-04\n",
      "\n",
      "At iterate   33    f=  6.45139D-01    |proj g|=  1.70505D-04\n",
      "\n",
      "At iterate   34    f=  6.45137D-01    |proj g|=  8.02883D-04\n",
      "\n",
      "At iterate   35    f=  6.45131D-01    |proj g|=  3.25914D-04\n",
      "\n",
      "At iterate   36    f=  6.45128D-01    |proj g|=  2.80913D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     36     41      1     0     0   2.809D-05   6.451D-01\n",
      "  F =  0.64512815692552361     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2000, 1000), learning_rate=&#x27;adaptive&#x27;,\n",
       "              learning_rate_init=1e-05, max_iter=500, solver=&#x27;lbfgs&#x27;,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2000, 1000), learning_rate=&#x27;adaptive&#x27;,\n",
       "              learning_rate_init=1e-05, max_iter=500, solver=&#x27;lbfgs&#x27;,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2000, 1000), learning_rate='adaptive',\n",
       "              learning_rate_init=1e-05, max_iter=500, solver='lbfgs',\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# params = { 'hidden_layer_sizes': [(200, 100, 90), (2000, 500, 80), (2000, 1500, 80), (3000, 1000, 80)]\n",
    "#             'solver': ['lbfgs']\n",
    "# }\n",
    "\n",
    "lrs = [1e-4, 0.5e-4, 1e-5, 1.5e-5, 2e-5, 1e-6, 1.5e-6, 2e-6 ]\n",
    "hiddenLayers = [(2500, 2000, 500), (2000, 1000, 500), ()]\n",
    "history = []\n",
    "# for lr in lrs:\n",
    "#     # TODO: Implement RandomSearch framework\n",
    "#     clf = MLPClassifier(hidden_layer_sizes=(5000), max_iter=10000, solver='lbfgs', activation='tanh', learning_rate='adaptive', learning_rate_init=lr, early_stopping=True, verbose=True)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     predictions = clf.predict(X_test)\n",
    "#     history.append(accuracy_score(y_test, predictions))\n",
    "clf = MLPClassifier(hidden_layer_sizes=(5000, 2000, 1000), max_iter=500, solver='lbfgs', activation='tanh', learning_rate='adaptive', learning_rate_init=1e-5, verbose=True, early_stopping=True)\n",
    "clf.fit(X_train, y_train)\n",
    "#predictions = clf.predict(X_test)\n",
    "# gs = GridSearchCV(clf)\n",
    "# print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.64      0.64      2484\n",
      "         1.0       0.64      0.64      0.64      2438\n",
      "\n",
      "    accuracy                           0.64      4922\n",
      "   macro avg       0.64      0.64      0.64      4922\n",
      "weighted avg       0.64      0.64      0.64      4922\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6412027631044291"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1080,  566],\n",
       "       [ 591, 1044]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save the classifier to a file\n",
    "with open(\"./Models/classifier_64perc.pkl\", \"wb\") as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.59      0.59      1051\n",
      "         1.0       0.63      0.64      0.63      1131\n",
      "\n",
      "    accuracy                           0.61      2182\n",
      "   macro avg       0.61      0.61      0.61      2182\n",
      "weighted avg       0.61      0.61      0.61      2182\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2500, 500), learning_rate=&#x27;adaptive&#x27;,\n",
       "              learning_rate_init=1e-05, max_iter=10000, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2500, 500), learning_rate=&#x27;adaptive&#x27;,\n",
       "              learning_rate_init=1e-05, max_iter=10000, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2500, 500), learning_rate='adaptive',\n",
       "              learning_rate_init=1e-05, max_iter=10000, verbose=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the saved classifier from the file\n",
    "with open(\"./Models/classifier_64perc.pkl\", \"rb\") as file:\n",
    "    clf = pickle.load(file)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.65      0.65      4403\n",
      "         1.0       0.64      0.65      0.65      4323\n",
      "\n",
      "    accuracy                           0.65      8726\n",
      "   macro avg       0.65      0.65      0.65      8726\n",
      "weighted avg       0.65      0.65      0.65      8726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_train)\n",
    "print(classification_report(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2500, 500), learning_rate=&#x27;adaptive&#x27;,\n",
       "              learning_rate_init=1e-05, max_iter=10000, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2500, 500), learning_rate=&#x27;adaptive&#x27;,\n",
       "              learning_rate_init=1e-05, max_iter=10000, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', early_stopping=True,\n",
       "              hidden_layer_sizes=(5000, 2500, 500), learning_rate='adaptive',\n",
       "              learning_rate_init=1e-05, max_iter=10000, verbose=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
